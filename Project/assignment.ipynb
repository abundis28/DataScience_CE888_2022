{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE888 Assignment 1 (21a2): Inexperienced Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools \n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, SCORERS, f1_score\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the filepath with the complete path to where the file was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   db_id                7000 non-null   object\n",
      " 1   query                7000 non-null   object\n",
      " 2   query_toks           7000 non-null   object\n",
      " 3   query_toks_no_value  7000 non-null   object\n",
      " 4   question             7000 non-null   object\n",
      " 5   question_toks        7000 non-null   object\n",
      " 6   sql                  7000 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 382.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(open(\"/Users/Enterprise/Desktop/OneDrive/Essex/Modules/DataScience/DataScience_CE888_2022/Project/spider/train_spider.json\", \"r\", encoding=\"utf8\"))\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>query_toks_no_value</th>\n",
       "      <th>question</th>\n",
       "      <th>question_toks</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>[SELECT, count, (, *, ), FROM, head, WHERE, ag...</td>\n",
       "      <td>[select, count, (, *, ), from, head, where, ag...</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>[How, many, heads, of, the, departments, are, ...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>[SELECT, name, ,, born_state, ,, age, FROM, he...</td>\n",
       "      <td>[select, name, ,, born_state, ,, age, from, he...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>[List, the, name, ,, born, state, and, age, of...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>[SELECT, creation, ,, name, ,, budget_in_billi...</td>\n",
       "      <td>[select, creation, ,, name, ,, budget_in_billi...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>[List, the, creation, year, ,, name, and, budg...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 0]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>[SELECT, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>[select, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>[What, are, the, maximum, and, minimum, budget...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 0]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>[SELECT, avg, (, num_employees, ), FROM, depar...</td>\n",
       "      <td>[select, avg, (, num_employees, ), from, depar...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>[What, is, the, average, number, of, employees...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 0]], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   db_id                                              query  \\\n",
       "0  department_management         SELECT count(*) FROM head WHERE age  >  56   \n",
       "1  department_management  SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2  department_management  SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3  department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4  department_management  SELECT avg(num_employees) FROM department WHER...   \n",
       "\n",
       "                                          query_toks  \\\n",
       "0  [SELECT, count, (, *, ), FROM, head, WHERE, ag...   \n",
       "1  [SELECT, name, ,, born_state, ,, age, FROM, he...   \n",
       "2  [SELECT, creation, ,, name, ,, budget_in_billi...   \n",
       "3  [SELECT, max, (, budget_in_billions, ), ,, min...   \n",
       "4  [SELECT, avg, (, num_employees, ), FROM, depar...   \n",
       "\n",
       "                                 query_toks_no_value  \\\n",
       "0  [select, count, (, *, ), from, head, where, ag...   \n",
       "1  [select, name, ,, born_state, ,, age, from, he...   \n",
       "2  [select, creation, ,, name, ,, budget_in_billi...   \n",
       "3  [select, max, (, budget_in_billions, ), ,, min...   \n",
       "4  [select, avg, (, num_employees, ), from, depar...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                       question_toks  \\\n",
       "0  [How, many, heads, of, the, departments, are, ...   \n",
       "1  [List, the, name, ,, born, state, and, age, of...   \n",
       "2  [List, the, creation, year, ,, name, and, budg...   \n",
       "3  [What, are, the, maximum, and, minimum, budget...   \n",
       "4  [What, is, the, average, number, of, employees...   \n",
       "\n",
       "                                                 sql  \n",
       "0  {'from': {'table_units': [['table_unit', 1]], ...  \n",
       "1  {'from': {'table_units': [['table_unit', 1]], ...  \n",
       "2  {'from': {'table_units': [['table_unit', 0]], ...  \n",
       "3  {'from': {'table_units': [['table_unit', 0]], ...  \n",
       "4  {'from': {'table_units': [['table_unit', 0]], ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances selection\n",
    "\n",
    "1000 questions that query a numerical value (average, min, max, count, sum)  are going to be selected. This list of selected instances will have the presence of questions with different levels of difficulty. This level of difficulty will be determined based on the presence of SQL keywords are found in the target SQL query; in other words, how many `JOIN`, `GROUP BY`, `ORDER BY`, `INTERSECT`, etc... are found in each query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: 464\n",
      "min: 165\n",
      "max: 233\n",
      "sum: 243\n",
      "Final size of filtered dataset: 923\n"
     ]
    }
   ],
   "source": [
    "total_avg = 0\n",
    "total_min = 0\n",
    "total_max = 0\n",
    "total_count = 0\n",
    "total_sum = 0\n",
    "list_filtered = []\n",
    "add_flag = False\n",
    "\n",
    "for index, tokens in enumerate(df[\"query_toks\"].values.tolist()):\n",
    "    if (\"avg\" in tokens):\n",
    "        add_flag = True\n",
    "        total_avg += 1\n",
    "    if (\"min\" in tokens):\n",
    "        add_flag = True\n",
    "        total_min += 1\n",
    "    if (\"max\" in tokens):\n",
    "        add_flag = True\n",
    "        total_max += 1\n",
    "    if (\"count\" in tokens):\n",
    "        total_count += 1\n",
    "    if (\"sum\" in tokens):\n",
    "        add_flag = True\n",
    "        total_sum += 1\n",
    "    if add_flag:\n",
    "        list_filtered.append(df.iloc[index])\n",
    "    add_flag = False\n",
    "\n",
    "print(\"avg: %d\" % total_avg)\n",
    "print(\"min: %d\" % total_min)\n",
    "print(\"max: %d\" % total_max)\n",
    "print(\"sum: %d\" % total_sum)\n",
    "\n",
    "print(\"Final size of filtered dataset: {}\".format(filtered_df_size := len(list_filtered)))\n",
    "df_filtered = pd.DataFrame(list_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_avg</th>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_min</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_max</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sum</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Keywords\n",
       "total_avg       464\n",
       "total_min       165\n",
       "total_max       233\n",
       "total_sum       243"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [total_avg,total_min,total_max,total_sum]\n",
    "index_names = [\"total_avg\",\"total_min\",\"total_max\",\"total_sum\"]\n",
    "keyword_df = pd.DataFrame(data, index=index_names, columns=[\"Keywords\"])\n",
    "keyword_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was decided that given the recommendation of choosing approximately 1000 instances, count-related queries have been excluded of the filtered dataframe because it increased by a very large margin the size of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>query_toks_no_value</th>\n",
       "      <th>question</th>\n",
       "      <th>question_toks</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>[SELECT, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>[select, max, (, budget_in_billions, ), ,, min...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>[What, are, the, maximum, and, minimum, budget...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 0]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>[SELECT, avg, (, num_employees, ), FROM, depar...</td>\n",
       "      <td>[select, avg, (, num_employees, ), from, depar...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>[What, is, the, average, number, of, employees...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 0]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>farm</td>\n",
       "      <td>SELECT avg(Working_Horses) FROM farm WHERE Tot...</td>\n",
       "      <td>[SELECT, avg, (, Working_Horses, ), FROM, farm...</td>\n",
       "      <td>[select, avg, (, working_horses, ), from, farm...</td>\n",
       "      <td>What is the average number of working horses o...</td>\n",
       "      <td>[What, is, the, average, number, of, working, ...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>farm</td>\n",
       "      <td>SELECT avg(Working_Horses) FROM farm WHERE Tot...</td>\n",
       "      <td>[SELECT, avg, (, Working_Horses, ), FROM, farm...</td>\n",
       "      <td>[select, avg, (, working_horses, ), from, farm...</td>\n",
       "      <td>Give the average number of working horses on f...</td>\n",
       "      <td>[Give, the, average, number, of, working, hors...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>farm</td>\n",
       "      <td>SELECT max(Cows) ,  min(Cows) FROM farm</td>\n",
       "      <td>[SELECT, max, (, Cows, ), ,, min, (, Cows, ), ...</td>\n",
       "      <td>[select, max, (, cows, ), ,, min, (, cows, ), ...</td>\n",
       "      <td>What are the maximum and minimum number of cow...</td>\n",
       "      <td>[What, are, the, maximum, and, minimum, number...</td>\n",
       "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    db_id                                              query  \\\n",
       "3   department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4   department_management  SELECT avg(num_employees) FROM department WHER...   \n",
       "24                   farm  SELECT avg(Working_Horses) FROM farm WHERE Tot...   \n",
       "25                   farm  SELECT avg(Working_Horses) FROM farm WHERE Tot...   \n",
       "26                   farm            SELECT max(Cows) ,  min(Cows) FROM farm   \n",
       "\n",
       "                                           query_toks  \\\n",
       "3   [SELECT, max, (, budget_in_billions, ), ,, min...   \n",
       "4   [SELECT, avg, (, num_employees, ), FROM, depar...   \n",
       "24  [SELECT, avg, (, Working_Horses, ), FROM, farm...   \n",
       "25  [SELECT, avg, (, Working_Horses, ), FROM, farm...   \n",
       "26  [SELECT, max, (, Cows, ), ,, min, (, Cows, ), ...   \n",
       "\n",
       "                                  query_toks_no_value  \\\n",
       "3   [select, max, (, budget_in_billions, ), ,, min...   \n",
       "4   [select, avg, (, num_employees, ), from, depar...   \n",
       "24  [select, avg, (, working_horses, ), from, farm...   \n",
       "25  [select, avg, (, working_horses, ), from, farm...   \n",
       "26  [select, max, (, cows, ), ,, min, (, cows, ), ...   \n",
       "\n",
       "                                             question  \\\n",
       "3   What are the maximum and minimum budget of the...   \n",
       "4   What is the average number of employees of the...   \n",
       "24  What is the average number of working horses o...   \n",
       "25  Give the average number of working horses on f...   \n",
       "26  What are the maximum and minimum number of cow...   \n",
       "\n",
       "                                        question_toks  \\\n",
       "3   [What, are, the, maximum, and, minimum, budget...   \n",
       "4   [What, is, the, average, number, of, employees...   \n",
       "24  [What, is, the, average, number, of, working, ...   \n",
       "25  [Give, the, average, number, of, working, hors...   \n",
       "26  [What, are, the, maximum, and, minimum, number...   \n",
       "\n",
       "                                                  sql  \n",
       "3   {'from': {'table_units': [['table_unit', 0]], ...  \n",
       "4   {'from': {'table_units': [['table_unit', 0]], ...  \n",
       "24  {'from': {'table_units': [['table_unit', 1]], ...  \n",
       "25  {'from': {'table_units': [['table_unit', 1]], ...  \n",
       "26  {'from': {'table_units': [['table_unit', 1]], ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing complexity of filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of databases involved: 115\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of databases involved: \"+str(len(df_filtered[\"db_id\"].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of questions: 55\n",
      "Min length of questions: 7\n"
     ]
    }
   ],
   "source": [
    "questions_lengths = df_filtered[\"query_toks\"].apply(len)\n",
    "print(\"Max length of questions: {}\".format(max_q_len := np.max(questions_lengths)))\n",
    "print(\"Min length of questions: {}\".format(min_q_len := np.min(questions_lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A range from 7 to 55 tokens per query shows a sufficient variation in the difficulty of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram = sns.histplot(questions_lengths)\n",
    "fig = histogram.get_figure()\n",
    "fig.savefig(\"query_length_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a heavy skewness to the left side in the distribution of the sizes of the queries. This means that there are fare more queries with small/medium size. Given that the model is meant for inexperienced people to be able to query databases, it is fair to assume that complex/large queries are not going to be as common a short ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Enterprise/opt/anaconda3/envs/pandasenv/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='query_toks'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(questions_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of keywords per query: \t 4.819068\n",
      "Min number of keywords per query: \t 2\n",
      "Max number of keywords per query: \t 16\n"
     ]
    }
   ],
   "source": [
    "sql_keywords = [\"add\",\" add constraint\", \"all\", \"alter\", \"alter column\", \"alter table\", \"and\", \"any\", \"as\", \"asc\", \"backup database\", \"between\", \"case\", \"check\", \"column\", \"constraint\", \"create\", \"create database\", \"create index\", \"create or replace view\", \"create table\", \"create procedure\", \"create unique index\", \"create view\", \"database\", \"default\", \"delete\", \"desc\", \"distinct\", \"drop\", \"drop column\", \"drop constraint\", \"drop database\", \"drop default\", \"drop index\", \"drop table\", \"drop view\", \"exec\", \"exists\", \"foreign key\", \"from\", \"full outer join\", \"group by\", \"having\", \"in\", \"index\", \"inner join\", \"insert into\", \"insert into select\", \"is null\", \"is not null\", \"join left\", \"join\", \"like\", \"limit\", \"not\", \"not null\", \"or\", \"order by\", \"outer join\", \"primary key\", \"procedure\", \"right join\", \"rownum\", \"select\", \"select distinct\", \"select into\", \"select top\", \"set\", \"table\", \"top\", \"truncate table\", \"union\", \"union all\", \"unique\", \"update\", \"values\", \"view\", \"where\"]\n",
    "\n",
    "list_sum_keywords = []\n",
    "sum = 0\n",
    "for query in df_filtered[\"query_toks_no_value\"]:\n",
    "    for token in query:\n",
    "        if token in sql_keywords:\n",
    "            sum += 1\n",
    "    list_sum_keywords.append(sum)\n",
    "    sum = 0\n",
    "\n",
    "print(\"Average number of keywords per query: \\t %f\" % np.mean(list_sum_keywords))\n",
    "print(\"Min number of keywords per query: \\t %d\" % np.min(list_sum_keywords))\n",
    "print(\"Max number of keywords per query: \\t %d\" % np.max(list_sum_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SQL queries contain an average of a little bit under 5 keywords per training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram = sns.histplot(list_sum_keywords)\n",
    "fig = histogram.get_figure()\n",
    "fig.savefig(\"query_keywords_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of keywords present per query is skewed to the right. This means that the number of keywords per query is mostly small but the average is still decent. That, added to the fact that the length range seems also acceptable, leads to the conclusion that the selected training instances are suitable for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the filtered dataframe in separate training and testing datasets (80% training & 20% testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738 185\n",
      "738 185\n"
     ]
    }
   ],
   "source": [
    "y_df = df_filtered[\"query_toks_no_value\"].copy()\n",
    "X_df = df_filtered[\"question_toks\"].copy()\n",
    "\n",
    "# Create separate training and test sets. we'll use the training set for steps 3--6\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=50)  \n",
    "# by setting a random_state above, we make sure anytime we run this line we end up with the same train and test sets\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset encoding of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data will be encoded in \"cubes\" and the dimensions of the cubes will represent the tokens present in each of the two components using a one-hot encoding approach. The dimensions of each cube will be arranged as follows: num_queries * max_num_tokens * num_tokens_in_dict.\n",
    "\n",
    "For example, in our filtered dataframe we have 923 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_questions = []\n",
    "nl_tokens = []\n",
    "sql_queries = []\n",
    "sql_tokens = []\n",
    "max_query_len = 0\n",
    "max_question_len = 0\n",
    "\n",
    "for index,_ in enumerate(X_train.values.tolist()):\n",
    "    nl_questions.append(X_train.iloc[index])\n",
    "    sql_queries.append(y_train.iloc[index])\n",
    "\n",
    "    # Determine max length of input and output training instances.\n",
    "    if len(X_train.iloc[index]) > max_question_len:\n",
    "        max_question_len = len(X_train.iloc[index])\n",
    "    if len(y_train.iloc[index]) > max_query_len:\n",
    "        max_query_len = len(y_train.iloc[index])\n",
    "\n",
    "    # Insert tokens into \"dictionary\" if not present yet.\n",
    "    for token_nl in X_train.iloc[index]:\n",
    "        if token_nl not in nl_tokens:\n",
    "            nl_tokens.append(token_nl)\n",
    "    for token_sql in y_train.iloc[index]:\n",
    "        if token_sql not in sql_tokens:\n",
    "            sql_tokens.append(token_sql)\n",
    "\n",
    "# Sort the dictionaries.\n",
    "sql_tokens = sorted(sql_tokens)\n",
    "nl_tokens = sorted(nl_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input questions: 738\n",
      "Number of output sql queries: 738\n",
      "Number of question tokens: 1009\n",
      "Number of queries tokens: 615\n",
      "Max length of questions: 36\n",
      "Max length of queries: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of input questions: %d\" % len(nl_questions))\n",
    "print(\"Number of output sql queries: %d\" % len(sql_queries))\n",
    "print(\"Number of question tokens: {}\".format(num_nl_tokens := len(nl_tokens)))\n",
    "print(\"Number of queries tokens: {}\".format(num_sql_tokens := len(sql_tokens)))\n",
    "print(\"Max length of questions: %d\" % max_question_len)\n",
    "print(\"Max length of queries: %d\" % max_query_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create proper dictionaries of tokens to improve time complexity of populating dataset cubes.\n",
    "nl_tokens_index = dict()\n",
    "sql_tokens_index = dict()\n",
    "\n",
    "for index, token in enumerate(nl_tokens):\n",
    "    nl_tokens_index[token] = index\n",
    "\n",
    "for index, token in enumerate(sql_tokens):\n",
    "    sql_tokens_index[token] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 738 // Max length of questions: 36 // Number of tokens in dictionary: 1009\n"
     ]
    }
   ],
   "source": [
    "# Create cubes and populate them with the one-hot encoding.\n",
    "encoder_input_cube = np.zeros((len(nl_questions), max_question_len, num_nl_tokens), dtype=\"float32\")\n",
    "decoder_input_cube = np.zeros((len(nl_questions), max_query_len, num_sql_tokens), dtype=\"float32\")\n",
    "decoder_output_cube = np.zeros((len(nl_questions), max_query_len, num_sql_tokens), dtype=\"float32\")\n",
    "\n",
    "# Iterate through both lists of NL questions and SQL queries.\n",
    "for i, (question, query) in enumerate(zip(nl_questions, sql_queries)):\n",
    "    # Iterate through each token of the NL question and mark the corresponding space in the cube \n",
    "    #       with a 1.0 if it is present.\n",
    "    for j, token in enumerate(question):\n",
    "        encoder_input_cube[i, j, nl_tokens_index[token]] = 1.0\n",
    "    # Iterate through each token of the SQL question and follow the same procedure for both decoders\n",
    "    #       keeping in mind that the output decoder is goes 1-timestep ahead.\n",
    "    for j, token in enumerate(query):\n",
    "        decoder_input_cube[i, j, sql_tokens_index[token]] = 1.0\n",
    "        if j > 0:\n",
    "            decoder_output_cube[i, j - 1, sql_tokens_index[token]] = 1.0\n",
    "\n",
    "print(\"Number of training instances: %d // Max length of questions: %d // Number of tokens in dictionary: %d\" % (len(encoder_input_cube), len(encoder_input_cube[0]), len(encoder_input_cube[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_questions_test = []\n",
    "nl_tokens_test = []\n",
    "sql_queries_test = []\n",
    "sql_tokens_test = []\n",
    "max_query_len_test = 0\n",
    "max_question_len_test = 0\n",
    "\n",
    "for index,_ in enumerate(X_test.values.tolist()):\n",
    "    nl_questions_test.append(X_test.iloc[index])\n",
    "    sql_queries_test.append(y_test.iloc[index])\n",
    "\n",
    "    # Determine max length of input and output testing instances.\n",
    "    if len(X_test.iloc[index]) > max_question_len_test:\n",
    "        max_question_len_test = len(X_test.iloc[index])\n",
    "    if len(y_test.iloc[index]) > max_query_len_test:\n",
    "        max_query_len_test = len(y_test.iloc[index])\n",
    "\n",
    "    # Insert tokens into \"dictionary\" if not present yet.\n",
    "    for token_nl in X_test.iloc[index]:\n",
    "        if token_nl not in nl_tokens_test:\n",
    "            nl_tokens_test.append(token_nl)\n",
    "    for token_sql in y_test.iloc[index]:\n",
    "        if token_sql not in sql_tokens_test:\n",
    "            sql_tokens_test.append(token_sql)\n",
    "\n",
    "# Sort the dictionaries.\n",
    "sql_tokens_test = sorted(sql_tokens_test)\n",
    "nl_tokens_test = sorted(nl_tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input questions testing: 185\n",
      "Number of output sql queries testing: 185\n",
      "Number of question tokens testing: 526\n",
      "Number of queries tokens testing: 378\n",
      "Max length of questions testing: 43\n",
      "Max length of queries testing : 69\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of input questions testing: %d\" % len(nl_questions_test))\n",
    "print(\"Number of output sql queries testing: %d\" % len(sql_queries_test))\n",
    "print(\"Number of question tokens testing: {}\".format(num_nl_tokens_test := len(nl_tokens_test)))\n",
    "print(\"Number of queries tokens testing: {}\".format(num_sql_tokens_test := len(sql_tokens_test)))\n",
    "print(\"Max length of questions testing: %d\" % max_question_len_test)\n",
    "print(\"Max length of queries testing : %d\" % max_query_len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create proper dictionaries of tokens to improve time complexity of populating dataset cubes.\n",
    "nl_tokens_index_test = dict()\n",
    "sql_tokens_index_test = dict()\n",
    "\n",
    "for index, token in enumerate(nl_tokens_test):\n",
    "    nl_tokens_index_test[token] = index\n",
    "\n",
    "for index, token in enumerate(sql_tokens_test):\n",
    "    sql_tokens_index_test[token] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 185 // Max length of questions: 43 // Number of tokens in dictionary: 526\n"
     ]
    }
   ],
   "source": [
    "# Create cubes and populate them with the one-hot encoding.\n",
    "encoder_input_cube_test = np.zeros((len(nl_questions_test), max_question_len_test, num_nl_tokens_test), dtype=\"float32\")\n",
    "decoder_input_cube_test = np.zeros((len(nl_questions_test), max_query_len_test, num_sql_tokens_test), dtype=\"float32\")\n",
    "decoder_output_cube_test = np.zeros((len(nl_questions_test), max_query_len_test, num_sql_tokens_test), dtype=\"float32\")\n",
    "\n",
    "# Iterate through both lists of NL questions and SQL queries.\n",
    "for i, (question, query) in enumerate(zip(nl_questions_test, sql_queries_test)):\n",
    "    # Iterate through each token of the NL question and mark the corresponding space in the cube \n",
    "    #       with a 1.0 if it is present.\n",
    "    for j, token in enumerate(question):\n",
    "        encoder_input_cube_test[i, j, nl_tokens_index_test[token]] = 1.0\n",
    "    # Iterate through each token of the SQL question and follow the same procedure for both decoders\n",
    "    #       keeping in mind that the output decoder is goes 1-timestep ahead.\n",
    "    for j, token in enumerate(query):\n",
    "        decoder_input_cube_test[i, j, sql_tokens_index_test[token]] = 1.0\n",
    "        if j > 0:\n",
    "            decoder_output_cube_test[i, j - 1, sql_tokens_index_test[token]] = 1.0\n",
    "\n",
    "print(\"Number of training instances: %d // Max length of questions: %d // Number of tokens in dictionary: %d\" % (len(encoder_input_cube_test), len(encoder_input_cube_test[0]), len(encoder_input_cube_test[0][0])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2351d84cf4fd304e6b460f6e47aa147fc073fde37b2ce751d158297c8be418"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('pandasenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
